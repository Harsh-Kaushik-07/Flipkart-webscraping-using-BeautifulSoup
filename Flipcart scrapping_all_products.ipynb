{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping the FlipKart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Heena\\anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_generator(product_name):\n",
    "    base_url = 'https://www.flipkart.com/search?q='\n",
    "    complete_url = base_url+product_name\n",
    "    return complete_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_details_scraping_category_1(url):\n",
    "    products=[]              \n",
    "    prices=[]                \n",
    "    ratings=[]               \n",
    "    apps = []                \n",
    "    os = []                  \n",
    "    hd = []                  \n",
    "    sound = []\n",
    "    offer= []\n",
    "    delivery_type= []\n",
    "    reviews=[]\n",
    "    other_offers=[]\n",
    "    actual_price=[]\n",
    "    specs=[]\n",
    "    \n",
    "    for x in range(20):\n",
    "        link=url+'&page='+str(x)\n",
    "#         print(link)\n",
    "\n",
    "        page = requests.get(link)\n",
    "        soup = bs(page.content, 'html.parser')\n",
    "        name=soup.find('div',class_=\"_4rR01T\")\n",
    "    \n",
    "        specification=soup.find('div',class_=\"fMghEO\")\n",
    "#         for each in specification:\n",
    "#             spec=each.find_all('li',class_='rgWa7D')\n",
    "        price=soup.find('div',class_='_30jeq3 _1_WHN1')\n",
    "        for data in soup.findAll('div',class_='_3pLy-c row'):\n",
    "            names=data.find('div', attrs={'class':'_4rR01T'})\n",
    "            price=data.find('div', attrs={'class':'_30jeq3 _1_WHN1'})\n",
    "            actual_prices=data.find('div', attrs={'class':'_3I9_wc _27UcVY'})\n",
    "            offers=data.find('div',attrs={'class':'_3Ay6Sb'})\n",
    "            rating=data.find('div',attrs={'class':'_3LWZlK'})\n",
    "            review=data.find('span',attrs={'class':'_2_R_DZ'})\n",
    "            specification = data.find('div', attrs={'class':'fMghEO'})\n",
    "#         for each in specification:\n",
    "#             col=each.find_all('li', attrs={'class':'rgWa7D'})\n",
    "#             app =col[0].text\n",
    "#             os_ = col[1].text\n",
    "#             hd_ = col[2].text\n",
    "#             sound_ = col[3].text\n",
    "            try:\n",
    "                products.append(names.text) \n",
    "                prices.append(price.text)\n",
    "                specs.append(specification.text)\n",
    "#             apps.append(app)\n",
    "#             os.append(os_) \n",
    "#             hd.append(hd_) \n",
    "#             sound.append(sound_)\n",
    "                actual_price.append(actual_prices.text)\n",
    "                offer.append(offers.text)\n",
    "                ratings.append(rating.text)\n",
    "                reviews.append(review.text)\n",
    "            except AttributeError:\n",
    "                    pass\n",
    "\n",
    "\n",
    "    a={'Product Name':products,'Specifications':specs,'Actual Price':actual_price,'New Price':prices,'Discount Percentage':offer,'Ratings':ratings,'Rating and Review Count':reviews}\n",
    "    df=pd.DataFrame.from_dict(a,orient ='index')\n",
    "    df=df.transpose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_details_scraping_category_2(url):\n",
    "    products=[]              \n",
    "    prices=[]                \n",
    "    ratings=[]               \n",
    "    apps = []                \n",
    "    os = []                  \n",
    "    hd = []                  \n",
    "    sound = []\n",
    "    offer= []\n",
    "    delivery_type= []\n",
    "    reviews=[]\n",
    "    other_offers=[]\n",
    "    actual_price=[]\n",
    "    specs=[]\n",
    "         \n",
    "    for x in range(20):\n",
    "        link=url+'&page='+str(x)\n",
    "#         print(link)\n",
    "\n",
    "        page = requests.get(link)\n",
    "        soup = bs(page.content, 'html.parser') \n",
    "\n",
    "        for data in soup.findAll('div',class_='_4ddWXP'):\n",
    "            \n",
    "            names=data.find('a', attrs={'class':'s1Q9rs'})\n",
    "            price=data.find('div', attrs={'class':'_30jeq3'})\n",
    "            actual_prices=data.find('div', attrs={'class':'_3I9_wc'})\n",
    "            offers=data.find('div',attrs={'class':'_3Ay6Sb'})\n",
    "            rating=data.find('div',attrs={'class':'_3LWZlK'})\n",
    "            review=data.find('span',attrs={'class':'_2_R_DZ'})\n",
    "            specification = data.find('div', attrs={'class':'_3Djpdu'})\n",
    "#         for each in specification:\n",
    "#             col=each.find_all('li', attrs={'class':'rgWa7D'})\n",
    "#             app =col[0].text\n",
    "#             os_ = col[1].text\n",
    "#             hd_ = col[2].text\n",
    "#             sound_ = col[3].text\n",
    "            try:\n",
    "                products.append(names.text) \n",
    "                prices.append(price.text)\n",
    "                specs.append(specification.text)\n",
    "#             apps.append(app)\n",
    "#             os.append(os_) \n",
    "#             hd.append(hd_) \n",
    "#             sound.append(sound_)\n",
    "                actual_price.append(actual_prices.text)\n",
    "                offer.append(offers.text)\n",
    "                ratings.append(rating.text)\n",
    "                reviews.append(review.text)\n",
    "            except AttributeError:\n",
    "                    pass\n",
    "\n",
    "    a={'Product Name':products,'Specification':specs,'Actual Price':actual_price,'New Price':prices,'Discount Percentage':offer,'Rating':ratings,'Rating Count':reviews}\n",
    "    df=pd.DataFrame.from_dict(a,orient ='index')\n",
    "    df=df.transpose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_details_scraping_category_3(url):\n",
    "    products=[]              \n",
    "    prices=[]                \n",
    "    ratings=[]               \n",
    "    apps = []                \n",
    "    os = []                  \n",
    "    hd = []                  \n",
    "    sound = []\n",
    "    offer= []\n",
    "    delivery_type= []\n",
    "    reviews=[]\n",
    "    other_offers=[]\n",
    "    actual_price=[]\n",
    "    specs=[]\n",
    "    for x in range(20):\n",
    "        link=url+'&page='+str(x)\n",
    "\n",
    "\n",
    "        page = requests.get(link)\n",
    "        soup = bs(page.content, 'html.parser')\n",
    "        name=soup.find('div',class_=\"_2WkVRV\")\n",
    "    \n",
    "        specification=soup.find('a',class_=\"IRpwTa\")\n",
    "#         for each in specification:\n",
    "#             spec=each.find_all('li',class_='rgWa7D')\n",
    "        price=soup.find('div',class_='_30jeq3')\n",
    "        for data in soup.findAll('div',class_='_1xHGtK _373qXS'):\n",
    "            names=data.find('div', attrs={'class':'_2WkVRV'})\n",
    "            price=data.find('div', attrs={'class':'_30jeq3'})\n",
    "            actual_prices=data.find('div', attrs={'class':'_3I9_wc'})\n",
    "            offers=data.find('div',attrs={'class':'_3Ay6Sb'})\n",
    "#             rating=data.find('div',attrs={'class':'_3LWZlK'})\n",
    "#             review=data.find('span',attrs={'class':'_2_R_DZ'})\n",
    "            specification = data.find('a', attrs={'class':'IRpwTa'})\n",
    "#         for each in specification:\n",
    "#             col=each.find_all('li', attrs={'class':'rgWa7D'})\n",
    "#             app =col[0].text\n",
    "#             os_ = col[1].text\n",
    "#             hd_ = col[2].text\n",
    "#             sound_ = col[3].text\n",
    "            try:\n",
    "                products.append(names.text) \n",
    "                prices.append(price.text)\n",
    "                specs.append(specification.text)\n",
    "#             apps.append(app)\n",
    "#             os.append(os_) \n",
    "#             hd.append(hd_) \n",
    "#             sound.append(sound_)\n",
    "                actual_price.append(actual_prices.text)\n",
    "                offer.append(offers.text)\n",
    "#                 ratings.append(rating.text)\n",
    "#                 reviews.append(review.text)\n",
    "            except AttributeError:\n",
    "                    pass\n",
    "\n",
    "    a={'Product Name':products,'Specification':specs,'Actual Price':actual_price,'New Price':prices,'Discount Percentage':offer}\n",
    "    df=pd.DataFrame.from_dict(a,orient ='index')\n",
    "    df=df.transpose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the product details you need to fetch\n",
      "Nonegrocery\n"
     ]
    }
   ],
   "source": [
    "product_name = input(print(\"enter the product details you need to fetch\"))\n",
    "url = url_generator(product_name)\n",
    "#print(url)\n",
    "page = requests.get(url)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "\n",
    "data = soup.findAll('div',class_='_3pLy-c row')\n",
    "#print(data)\n",
    "data2 = soup.findAll('div',class_='_4ddWXP')\n",
    "#print(data2)\n",
    "if(data != []):\n",
    "    data = product_details_scraping_category_1(url)\n",
    "    \n",
    "elif(data2 != []):\n",
    "    data = product_details_scraping_category_2(url)\n",
    "else:\n",
    "    data = product_details_scraping_category_3(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Specification</th>\n",
       "      <th>Actual Price</th>\n",
       "      <th>New Price</th>\n",
       "      <th>Discount Percentage</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Madhuban Premium Seedless Raisins</td>\n",
       "      <td>75 g</td>\n",
       "      <td>₹75</td>\n",
       "      <td>₹18</td>\n",
       "      <td>76% off</td>\n",
       "      <td>3.7</td>\n",
       "      <td>(174)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Molsi's Cashews</td>\n",
       "      <td>75 g</td>\n",
       "      <td>₹129</td>\n",
       "      <td>₹54</td>\n",
       "      <td>58% off</td>\n",
       "      <td>4.3</td>\n",
       "      <td>(2,013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naturoz Popular California Almonds</td>\n",
       "      <td>500 g</td>\n",
       "      <td>₹825</td>\n",
       "      <td>₹375</td>\n",
       "      <td>54% off</td>\n",
       "      <td>4.3</td>\n",
       "      <td>(46,787)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whiskas Kitten (2-12 months) Mackeral 0.45 kg ...</td>\n",
       "      <td>500 g</td>\n",
       "      <td>₹160</td>\n",
       "      <td>₹171</td>\n",
       "      <td>37% off</td>\n",
       "      <td>4.1</td>\n",
       "      <td>(155)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Molsi's Royal Zahidi Dates</td>\n",
       "      <td>500 g</td>\n",
       "      <td>₹1,199</td>\n",
       "      <td>₹100</td>\n",
       "      <td>52% off</td>\n",
       "      <td>4.3</td>\n",
       "      <td>(7,111)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Specification  \\\n",
       "0                  Madhuban Premium Seedless Raisins          75 g   \n",
       "1                                    Molsi's Cashews          75 g   \n",
       "2                 Naturoz Popular California Almonds         500 g   \n",
       "3  Whiskas Kitten (2-12 months) Mackeral 0.45 kg ...         500 g   \n",
       "4                         Molsi's Royal Zahidi Dates         500 g   \n",
       "\n",
       "  Actual Price New Price Discount Percentage Rating Rating Count  \n",
       "0          ₹75       ₹18             76% off    3.7        (174)  \n",
       "1         ₹129       ₹54             58% off    4.3      (2,013)  \n",
       "2         ₹825      ₹375             54% off    4.3     (46,787)  \n",
       "3         ₹160      ₹171             37% off    4.1        (155)  \n",
       "4       ₹1,199      ₹100             52% off    4.3      (7,111)  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('Grocery.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total 6363 data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
